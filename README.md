# Confidence-Calibration-under-Distribution-Shift
This repository is dedicated to documenting state-of-the-art methods for confidence calibration of classification models under distribution shift, including papers and reproduction code for these methods. The distribution shift include three kinds: Label shift, Covariate shift, and Out-of-distribution.
## Confidence Calibration under Label Shift
1. [Posterior Re-calibration for Imbalanced Datasets](https://proceedings.neurips.cc/paper/2020/hash/5ca359ab1e9e3b9c478459944a2d9ca5-Abstract.html)
2. [LADE](https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html)

## Confidence calibration under Covariate Shift

## Confidence calibration under Out-of-distribution
